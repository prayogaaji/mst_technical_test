{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>section</th>\n",
       "      <th>heading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chicago</td>\n",
       "      <td>for-sale</td>\n",
       "      <td>Madden NFL 25 XBOX 360. Brand New!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paris.en</td>\n",
       "      <td>housing</td>\n",
       "      <td>looking for room to rent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newyork</td>\n",
       "      <td>for-sale</td>\n",
       "      <td>two DS game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seattle</td>\n",
       "      <td>housing</td>\n",
       "      <td>map</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singapore</td>\n",
       "      <td>services</td>\n",
       "      <td>Good Looking Asian Sensation N aughty Girl ---...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        city   section                                            heading\n",
       "0    chicago  for-sale                 Madden NFL 25 XBOX 360. Brand New!\n",
       "1   paris.en   housing                          looking for room to rent.\n",
       "2    newyork  for-sale                                        two DS game\n",
       "3    seattle   housing                                                map\n",
       "4  singapore  services  Good Looking Asian Sensation N aughty Girl ---..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Load the training data from JSON file\n",
    "train_data = pd.read_json('dataset/training.json', lines=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique cities: ['newyork' 'seattle' 'chicago' 'london' 'manchester' 'hyderabad' 'mumbai'\n",
      " 'delhi' 'singapore' 'bangalore' 'paris.en' 'geneva.en' 'zurich.en'\n",
      " 'frankfurt.en' 'kolkata.en' 'dubai.en']\n",
      "Unique categories: ['cell-phones' 'appliances' 'photography' 'video-games' 'housing' 'shared'\n",
      " 'temporary' 'wanted-housing' 'activities' 'artists' 'childcare' 'general'\n",
      " 'automotive' 'household-services' 'real-estate' 'therapeutic']\n",
      "Unique sections: ['for-sale' 'housing' 'community' 'services']\n"
     ]
    }
   ],
   "source": [
    "unique_cities = train_data['city'].unique()\n",
    "unique_categories = train_data['category'].unique()\n",
    "unique_sections = train_data['section'].unique()\n",
    "\n",
    "# Print unique values\n",
    "print(\"Unique cities:\", unique_cities)\n",
    "print(\"Unique categories:\", unique_categories)\n",
    "print(\"Unique sections:\", unique_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text data\n",
    "def preprocess_text(textdata):\n",
    "    processedText = []\n",
    "    \n",
    "    # Create Lemmatizer and Stemmer.\n",
    "    wordLemm = WordNetLemmatizer()\n",
    "    \n",
    "    # Defining regex patterns.\n",
    "    urlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "    userPattern       = '@[^\\s]+'\n",
    "    alphaPattern      = \"[^a-zA-Z0-9]\"\n",
    "    sequencePattern   = r\"(.)\\1\\1+\"\n",
    "    seqReplacePattern = r\"\\1\\1\"\n",
    "    \n",
    "    for tweet in textdata:\n",
    "        tweet = tweet.lower()\n",
    "        \n",
    "        # Replace all URls with 'URL'\n",
    "        tweet = re.sub(urlPattern,' URL',tweet)      \n",
    "        # Replace @USERNAME to 'USER'.\n",
    "        tweet = re.sub(userPattern,' USER', tweet)        \n",
    "        # Replace all non alphabets.\n",
    "        tweet = re.sub(alphaPattern, \" \", tweet)\n",
    "        # Replace 3 or more consecutive letters by 2 letter.\n",
    "        tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
    "\n",
    "        tweetwords = ''\n",
    "        for word in tweet.split():\n",
    "            # Checking if the word is a stopword.\n",
    "            #if word not in stopwordlist:\n",
    "            if len(word)>1:\n",
    "                # Lemmatizing the word.\n",
    "                word = wordLemm.lemmatize(word)\n",
    "                tweetwords += (word+' ')\n",
    "            \n",
    "        processedText.append(tweetwords)\n",
    "        \n",
    "    return processedText\n",
    "\n",
    "train_data['heading'] = preprocess_text(train_data['heading'].str.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/40115-c02h83xjq05d/mst/craigslist_classifier_env/lib/python3.9/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data['heading'], train_data['category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Initialize LinearSVC classifier\n",
    "classifier = LinearSVC()\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(classifier, 'text_classifier_model.joblib')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7559347181008902\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        activities       0.83      0.49      0.62        79\n",
      "        appliances       0.90      0.72      0.80       265\n",
      "           artists       0.76      0.54      0.63        89\n",
      "        automotive       0.88      0.77      0.82       233\n",
      "       cell-phones       0.97      0.91      0.94       365\n",
      "         childcare       0.88      0.72      0.80       239\n",
      "           general       0.58      0.44      0.50       197\n",
      "household-services       0.79      0.77      0.78       275\n",
      "           housing       0.67      0.44      0.53        55\n",
      "       photography       0.89      0.85      0.87       294\n",
      "       real-estate       0.77      0.67      0.72       240\n",
      "            shared       0.42      0.85      0.57       439\n",
      "         temporary       0.73      0.47      0.57       317\n",
      "       therapeutic       0.93      0.97      0.95       447\n",
      "       video-games       0.95      0.82      0.88       218\n",
      "    wanted-housing       0.77      0.78      0.77       292\n",
      "\n",
      "          accuracy                           0.76      4044\n",
      "         macro avg       0.79      0.70      0.73      4044\n",
      "      weighted avg       0.80      0.76      0.76      4044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Transform the testing data using the same TF-IDF vectorizer\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Predict categories for the testing data\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Generate classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "craigslist_classifier_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
